{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of total 104567\n",
      "Length of full datasets 104567\n",
      "Length of full dataset fc 2078\n",
      "an_leg_fc 447\n",
      "an_k5a_fc 1220\n",
      "can_nou_fc 411\n",
      "Length of full dataset fc batched 2078\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "\n",
    "LABEL_SESSION_NUM = \"label_session_1\"\n",
    "\n",
    "FINAL_CANDIDATES = \"_final_candidates\"\n",
    "\n",
    "DF = \"_df\"\n",
    "\n",
    "SENTENCES = \"_sent\"\n",
    "\n",
    "BATCHED = \"_batched\"\n",
    "\n",
    "ENCODING = 'utf-8-sig'\n",
    "\n",
    "an_leg = pd.read_csv(\"AN-LEG_df\", encoding='utf-8')\n",
    "\n",
    "an_k5a = pd.read_csv(\"AN-K5A_df\", encoding='utf-8')\n",
    "\n",
    "ca_nou = pd.read_csv(\"CA-NOU_df\", encoding='utf-8')\n",
    "\n",
    "total_length = len(an_leg) + len(ca_nou) + len(an_k5a)\n",
    "\n",
    "full_datasets = pd.concat([an_leg,an_k5a,ca_nou],ignore_index=True)\n",
    "\n",
    "if total_length != len(full_datasets):\n",
    "    print(\"ERRRROOOOOOORRRRRR\")\n",
    "\n",
    "print(\"Length of total\", total_length)\n",
    "print(\"Length of full datasets\",len(full_datasets))\n",
    "\n",
    "label_1_fc_df = full_datasets.loc[full_datasets['Final candidates'] == 1.]\n",
    "\n",
    "print(\"Length of full dataset fc\", len(label_1_fc_df))\n",
    "\n",
    "#Get final candidates out of each datasets\n",
    "an_leg_fc = an_leg[an_leg['Final candidates'] == 1.]\n",
    "an_k5a_fc = an_k5a[an_k5a['Final candidates'] == 1.]\n",
    "ca_nou_fc = ca_nou[ca_nou['Final candidates'] == 1.]\n",
    "\n",
    "an_leg_len = len(an_leg_fc)\n",
    "print(\"an_leg_fc\",an_leg_len)\n",
    "an_k5a_len = len(an_k5a_fc)\n",
    "print(\"an_k5a_fc\",an_k5a_len)\n",
    "ca_nou_len = len(ca_nou_fc)\n",
    "print(\"can_nou_fc\",ca_nou_len)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "num_batches_max = math.ceil(an_k5a_len/BATCH_SIZE)\n",
    "\n",
    "num_batches_an_leg = math.ceil(an_leg_len/BATCH_SIZE)\n",
    "\n",
    "num_batches_ca_nou = math.ceil(ca_nou_len/BATCH_SIZE)\n",
    "\n",
    "full_dataset_fc_batched = pd.DataFrame()\n",
    "\n",
    "for batch_idx in range(num_batches_max):\n",
    "    # max length\n",
    "    if batch_idx <= num_batches_an_leg: \n",
    "        an_leg_batch = an_leg_fc[batch_idx*BATCH_SIZE:(batch_idx+1)*BATCH_SIZE]\n",
    "        full_dataset_fc_batched = full_dataset_fc_batched.append(an_leg_batch,ignore_index=True)\n",
    "    if batch_idx <= num_batches_ca_nou:\n",
    "        ca_nou_batch = ca_nou_fc[batch_idx*BATCH_SIZE:(batch_idx+1)*BATCH_SIZE]\n",
    "        full_dataset_fc_batched = full_dataset_fc_batched.append(ca_nou_batch,ignore_index=True)\n",
    "    an_k5a_batch = an_k5a_fc[batch_idx*BATCH_SIZE:(batch_idx+1)*BATCH_SIZE]\n",
    "    full_dataset_fc_batched = full_dataset_fc_batched.append(an_k5a_batch,ignore_index=True)\n",
    "    \n",
    "\n",
    "print(\"Length of full dataset fc batched\", len(full_dataset_fc_batched))  \n",
    "if len(label_1_fc_df) != len(full_dataset_fc_batched):\n",
    "    print(\"ERRRROOOOOOORRRRRR\")\n",
    "\n",
    "\n",
    "#Write only the sentences to file for TURK - Would like to keep the DATA ID \n",
    "#full_dataset_fc_batched_sent = full_dataset_fc_batched[full_dataset_fc_batched['Data ID'] and full_dataset_fc_batched['Sentences']]\n",
    "#full_dataset_fc_batched_sent.to_csv(LABEL_SESSION_NUM+FINAL_CANDIDATES+BATCHED+SENTENCES, index=False, encoding='utf-8-sig')\n",
    "\n",
    "output_path = '../labeling_output/session_1/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "green_datasets.to_csv(output_path + LABEL_SESSION_NUM+DF,encoding=ENCODING)\n",
    "label_1_fc_df.to_csv(output_path+LABEL_SESSION_NUM+FINAL_CANDIDATES+DF, index=True,encoding=ENCODING)\n",
    "full_dataset_fc_batched.to_csv(output_path + LABEL_SESSION_NUM+FINAL_CANDIDATES+BATCHED+DF,encoding=ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag and set up for Turk \n",
    "\n",
    "#marked_df = pd.DataFrame({'text': marked_data}) # Turk needs a header called 'text'\n",
    "#marked_df.to_csv(self.final_candidates_filename + \"_marked.csv\", header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
